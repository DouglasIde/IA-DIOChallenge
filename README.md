<h1 align="center">ğŸ“¸ Converting Image to Text âœğŸ»</h1>
<img src="https://github.com/DouglasIde/IA-ImageToText/blob/main/inputs/README_files/douglas-tesseract-project-dio-challenge.jpg" alt="Imagem de capa do projeto do Douglas da DIO"
  target="_blank">

<div align="center">
  <em>
    IDE: <a href="https://visualstudio.microsoft.com/pt-br/">Visual Code</a><br><br>
  </em>
  
  <a href="https://www.linkedin.com/in/douglas-yugo/" target="_blank">
    <img src="https://img.shields.io/static/v1?label=Author&message=DouglasYugo&color=purple&style=for-the-badge&logo=LinkedIn" alt="Author: Douglas Yugo">
  </a>
  <img src="https://img.shields.io/static/v1?label=Language&message=C%23&color=purple&style=for-the-badge&logo=sharp" alt="Language: C#">
  <img src="https://img.shields.io/static/v1?label=Framework&message=.NET&color=purple&style=for-the-badge&logo=dotnet" alt="Framework: .NET">
</div>


<h1>ğŸ“ŒDescription</h1>
<p>The project was developed as part of the conclusion of the DIO Bootcamp, with a focus on exploring Generative Artificial Intelligence resources, such as OpenAI and GitHub Copilot.

The main aim of the project was to recognize text in images stored in the "inputs" folder. To do this, I created an API using C# and .NET, which captures the texts contained in the 
images and displays the results on the console. To read and extract the texts from the images, I used Tesseract, an open source OCR tool.</p><br>

<h1>ğŸ¤–Technologies</h1>
<li><strong><a href="https://copilot.microsoft.com/" target="_blank">Copilot</strong> : Creating images for the presentation.</li>
<li><strong><a href="https://dotnet.microsoft.com/pt-br/languages/csharp" target="_blank">C# and .NET</strong> : I used these technologies to create the API with Tesseract.</li> 
<li><strong><a href="https://github.com/tesseract-ocr/tesseract" target="_blank">Tesseract</strong> : To recognize text in images.</li><br>

<h1>âš Warning</h1>
<p>To use Tesseract, you'll need to download it to your machine. In <strong>Technologies</strong> you'll
find it with a link to all the documentation, including installation.

You also need to install the <strong>trainedddata</strong>, which is responsible for
teaching Tesseract about the languages it can find in the images. Each "traineddata" file has its own 
language.

The images you run Tesseract on should preferably be in black and white. Try to follow the example images
in the <strong>Inputs folder</strong></p><br>


